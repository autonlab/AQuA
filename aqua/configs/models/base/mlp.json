{
    "epochs": 15,
    "batch_size": 64,
    "lr": 0.001,
    "lr_drops": [],
    "layers": [],
    "p": 0.0
}