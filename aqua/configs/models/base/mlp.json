{
    "epochs": 30,
    "batch_size": 128,
    "lr": 0.005,
    "lr_drops": [],
    "layers": [],
    "p": 0.3
}